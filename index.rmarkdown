---
title: "Examing the Effects of Monetary Policy on Regional Unemployment in Australia: A Structural Vector Autoregression Analysis"
author: "Django Trueman-Greinke"

execute:
  echo: false
  
bibliography: references.bib
---


> **Abstract.** Using data from the Australian Bureau of Statistics, this paper attempts to understand how changes in monetary policy impact unemployment levels in different Australian states using a Structural Vector Autoregression (SVAR) approach.

> **Keywords.** Monetary policy, Unemployement, Regional Effects, Impluse Response Function, Structural Vector Autoregressions, Australia \# Introduction

Intro in progress

Plots below

# Data


```{r Data}
#| echo: false
#| message: false
#| warning: false

library(lubridate)
library(xtable)
library(mvtnorm)
library(plot3D)
library(HDInterval)

##Nominal GDP per capita
real.gdp <- readrba::read_rba(series_id = "GGDPCVGDP") 
real.gdp_temp <- xts::xts(real.gdp$value, real.gdp$date)
log.rgdp = log(real.gdp_temp)

##Cash Rate Target
crt <- readrba::read_rba(series_id = "FOOIRATCR") 
crt_temp <- xts::xts(crt$value, crt$date)

##Money Supply
MS <- readrba::read_rba(series_id = "DMAM1N") 
MS_temp <- xts::xts(MS$value, MS$date)


##Consumer Price Index
CPI <- readrba::read_rba(series_id = "GCPIAG") 
CPI_temp <- xts::xts(CPI$value, CPI$date)
D.CPI <- diff(CPI_temp)


##QLD Unemployment Rate

UER.QLD <- readabs::read_abs(series_id = "A84423284T") 
UER.QLD_temp <- xts::xts(UER.QLD$value, UER.QLD$date - days(1))

##NSW Unemployment Rate

UER.NSW <- readabs::read_abs(series_id = "A84423270C") 
UER.NSW_temp <- xts::xts(UER.NSW$value, UER.NSW$date - days(1))

##VIC Unemployment Rate

UER.VIC <- readabs::read_abs(series_id = "A84423350C") 
UER.VIC_temp <- xts::xts(UER.VIC$value, UER.VIC$date - days(1))

##WA Unemployment Rate

UER.WA <- readabs::read_abs(series_id = "A84423322V") 
UER.WA_temp <- xts::xts(UER.WA$value, UER.WA$date - days(1))



data <- as.data.frame(merge(log.rgdp, D.CPI, crt_temp, MS_temp, UER.QLD_temp, UER.NSW_temp, UER.VIC_temp, UER.WA_temp))

names <- c("Log(Real GDP)","First Diff: Consumer Price Index", "Cash Rate Target", "Money Supply", "Unemployment Rate: Queensland", "Unemployment Rate: New South Wales","Unemployment Rate: Victoria","Unemployment Rate: Western Australia")

data <- na.omit(data)[1:132,]

colnames(data) <- names

```


The data required can all be taken directly from the Australian Bureau of Statistics who provide data from 1959 to 2022 on GDP, government spending, government revenue, and debt data from 1988. They also provide data relating to the Gini coefficient, however I am unable to find the series ID for this at present.

Below are plots of each of the available variables over time.


```{r plots}
#| echo: false
#| message: false
#| warning: false

dates <- as.Date(rownames(data),format = "%Y-%m-%d")

units <- c("","", "", "", "Per cent per annum", "$ billion", "Percent", "Percent","Percent","Percent")

par(mfrow=c(2,2), mar=c(4,4,4,4))

for (i in 1:8){
  plot(dates, y=data[,i], main = paste(names[i]), ylab = paste(units[i]),xlab = "Date",type = "l",col = "blue",lwd = 2)
  
}

```


# Preliminary Results

## ACF and PACF plots


```{r (P)ACF plots}



par(mfrow=c(2,2), mar=c(4,4,4,4))
for(i in 1:8){
  acf(data[,i], main = paste(names[i]) )
pacf(data[,i], main = paste(names[i]))
}

```


##Integration order verification


```{r Integration}
#| echo: false
#| message: false
#| warning: false

results.adf0 <- data.frame("Variable" = character(),"Lag Order" = numeric(), "ADF Statistic" = numeric(), "p value" = numeric())


for (i in 1:8){
adf = tseries::adf.test(data[,i], k = 4)
results.adf0[i,1] <- paste(names[i])
results.adf0[i,2] <- adf$parameter
results.adf0[i,3] <- adf$statistic
results.adf0[i,4] <- adf$p.value

}


results.adf1 <- data.frame("Variable" = character(),"Lag Order" = numeric(), "ADF Statistic" = numeric(), "p value" = numeric())
for (i in 1:8){
  if (results.adf0[i,4]>0.05 & results.adf0[i,4]<1){
diff_adf = tseries::adf.test(diff(data[,i]), k = 3)
results.adf1[i,1] <- paste(names[i])
results.adf1[i,2] <- diff_adf[2]
results.adf1[i,3] <- diff_adf[1]
results.adf1[i,4] <- diff_adf[4]
  } else{
results.adf1[i,1] <- paste(names[i])
results.adf1[i,2] <- "N/A"
results.adf1[i,3] <- "N/A"
results.adf1[i,4] <- "N/A" }
}

results.adf2 <- data.frame("Variable" = character(),"Lag Order" = numeric(), "ADF Statistic" = numeric(), "p value" = numeric())
for (i in 1:8){
  if (results.adf1[i,4]>0.05 & results.adf1[i,4]<1){
diff_adf = tseries::adf.test(diff(diff(data[,i])), k = 3)
results.adf2[i,1] <- paste(names[i])
results.adf2[i,2] <- diff_adf[2]
results.adf2[i,3] <- diff_adf[1]
results.adf2[i,4] <- diff_adf[4]
  }else{
results.adf2[i,1] <- paste(names[i])
results.adf2[i,2] <- "N/A"
results.adf2[i,3] <- "N/A"
results.adf2[i,4] <- "N/A" }
}

print(results.adf0)
print(results.adf1)
print(results.adf2)


```


# Methodology

Below is the Structural Vector Autoregression (SVAR) modelrequired to capture the dynamics between the variables.

\begin{align}
B_0 Y_t = b_0 + B_1 y_{t-1} +\dots +B_p y_{t-p} + u_t
\end{align} \begin{align}
u_t|Y_{t-1}~iid(0_N,I_N)
\end{align}

Where:

$Y_{t}$ is an $N\times 1$ vector of endogenous variables, including the Gini coefficient, government spending, revenue, GDP, and debt.

$B_0$ is an $N \times N$ structural matrix capturing comtemporaneous relationships between variables.

$u_t$ is an $N\times 1$ vector of independent structural shocks, conditional on $Y_{t-1}$.

Using this model I will give me an insight into dynamic relationships between government spending, revenue and income inequality. Impulse response functions and forecast error variance decompositions (FEVDs) will be used to analyse the effects of fiscal policy on income inequality.

Using both of these techniques together, I will gain an understanding of the long- and short-run impacts of shocks to government spending and taxation.


## Estimation Framework
Starting with the reduced form, we can present the likelihood function as a normal-inverse Wishart distribution for $(A,\Sigma)$

\begin{gather}
Y = XA + E \\
\\ E|X \sim MN_{T \times N}(0_{T \times N},\Sigma,I_T) 
\end{gather}

\begin{gather}
L(A,\Sigma|Y,X) \propto det(\Sigma)^{-\frac{T}{2}} exp \left\{-\frac{1}{2} tr \left[ \Sigma^{-1}(Y-XA)'(Y-XA) \right] \right\} \\
\\ = det(\Sigma)^{-\frac{T}{2}} exp \left\{-\frac{1}{2} tr \left[ \Sigma^{-1}(A-\hat{A})'X'X(A-\hat{A}) \right] \right\} exp \left\{-\frac{1}{2} tr \left[\Sigma^{-1}(Y-X \hat{A})'(Y-X \hat{A}) \right] \right\} \\
\end{gather}

where:



$$Y_t=\begin{pmatrix}  GDP_t &= \text{Real GDP}
\\ CPI_t  &= \text{Consumer Price Index}
\\ CRT_p  &= \text{Cash Rate Target GDP}
\\ M1_t  &= \text{Money Supply}
\\ UR_t  &= \text{State Specific Unemployment Rate}
\end{pmatrix}$$


\begin{gather}
\hat{A} = (X'X)^{-1}X'Y
\end{gather}

Hence:

\begin{gather}
L(A,\Sigma|Y,X) = NIW_{K\times N}(\hat{A}, (X'X)^{-1},(Y-X\hat{A})'(Y-X\hat{A}), T-N-K)
\end{gather}


This leads to joint prior distribution for $(A, \Sigma)$ of the same form:

\begin{gather}

p(A,\Sigma) = p(A|\Sigma) p(\Sigma) \\
A|\Sigma \sim MN_{K \times N} (\underline{A}, \Sigma , \underline{V}) \\
\Sigma \sim IW_{N}(\underline{S},\underline{\nu})
\end{gather}

The full conditional posterior is, therefore, given by:

\begin{gather}
p(A,\Sigma |Y, X) = p(A|Y, X, \Sigma) p(\Sigma|Y,X) \\
p(A|Y,X,\Sigma) = MN_{K \times N} (\bar{A}, \Sigma , \bar{V}) \\
p(\Sigma|Y, X) = IW_{N}(\bar{S},\bar{\nu})
\end{gather}

with parameters:

\begin{gather}
\bar{V} = (X^{'}X+ \underline{V}^{-1})^{-1} \\ 
\\ \bar{A} = \bar{V}(X^{'}Y+\underline{V}^{-1} \underline{A}) \\ 
\\ \bar{\nu} = T + \underline{\nu} \\ 
\\ \bar{S} = \underline{S} + Y^{'}Y +  \underline{A}^{'}\underline{V}^{-1}\underline{A} - \bar{A}^{'}\bar{V}^{-1}\bar{A}
\end{gather}


The following function uses the Minnesota prior to set priors for $V$, $A$, $\nu,$ and $S$

```{R - Setting Priors}
#| echo: true


calc.priors <- function(p, X, Y){
  
  
  
  A.hat = solve(t(X)%*%X)%*%(t(X)%*%Y)
  Sigma.hat = t(Y-X%*%A.hat)%*%(Y-X%*%A.hat)/T
  N = ncol(Y)
    
  #Setting Kappas
  kappa.1 <- 0.02^2
  kappa.2 <-100
  
  K = 1 + (p*N)
  
  
  A.prior     = matrix(0,nrow(A.hat),ncol(A.hat))
  A.prior[2:(N+1),] = diag(N)
  V.prior     = diag(c(kappa.2,kappa.1*((1:p)^(-2))%x%rep(1,N)))
  S.prior     = diag(diag(Sigma.hat))
  nu.prior    = N+1
  
  priors <- list(A.prior = A.prior , V.prior=V.prior, S.prior=S.prior, nu.prior=nu.prior)
  
  return(priors)
}

```





$$\begin{align}
y_t &= \mu_0 + A_1 y_{t-1} + \dots + A_p y_{t-p} + \varepsilon_t\\
\text{where }B_0^{-1}u_t &= \varepsilon_t| Y_{t-1} \sim _{iid} ( 0, \Sigma)\\
\Sigma &= B_0^{-1}B_0^{-1'}
\end{align}$$








Using these priors and the function below, we can calculate posteriors $A$, $B$, and $\Sigma$


```{R }
#| echo: true


calc.posteriors <- function (p, S, X, Y, priors){
  
  N = ncol(Y)
  A.prior <- priors$A.prior
  V.prior <- priors$V.prior
  S.prior <- priors$S.prior
  nu.prior <- priors$nu.prior
  
  V.bar.inv   = (t(X)%*%X) + diag(1/diag(V.prior))
  V.bar       = solve(V.bar.inv)
  
  A.bar       = V.bar%*%(t(X)%*%Y + diag(1/diag(V.prior))%*%A.prior)
  nu.bar      = nrow(Y) + nu.prior
  
  S.bar       = S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar
  S.bar.inv   = solve(S.bar)
 
 
  
  Sigma.posterior.inv   = rWishart(S, df=nu.bar, Sigma=S.bar.inv)
Sigma.posterior   = apply(Sigma.posterior.inv,3,solve)
Sigma.posterior   = array(Sigma.posterior,c(N,N,S))
A.posterior       = array(rnorm(prod(c(dim(A.bar),S))),c(dim(A.bar),S))
L                 = t(chol(V.bar))
B.posterior = array(NA, c(N,N,S))
B1.posterior = array(NA,c(N,(1+N*p),S))
  


for (s in 1:S){
  chol.sigma = chol(Sigma.posterior[,,s])
  A.posterior[,,s]= A.bar + L%*%A.posterior[,,s]%*%chol.sigma
  B.posterior[,,s]= t(chol.sigma)
  B1.posterior[,,s]= B.posterior[,,s]%*%t(A.posterior[,,s])
}
  
  posterior = list(A.posterior = A.posterior, B.posterior = B.posterior, Sigma.posterior = Sigma.posterior, B1.posterior = B1.posterior)
  
  return(posterior)
}




```


## Extended model formulation


```{R}
#| echo: true
prior.ex <- function(data, p = 1, lambda_3 = 1, lambda_4 = 1){
  
  N = ncol(data)
  M = (N*p)+1
  
  in.obvs.Y <- matrix(data[1:p,], ncol = N)
  y.bar     = colMeans(in.obvs.Y)
    
  Y_star    = rbind(diag(y.bar)/lambda_3, y.bar/lambda_4)
  X_star    = as.matrix(c(rep(0, N), 1/lambda_4))
  for (i in 1:p) {
    X_star  = cbind(Y_star, X_star)
  }
  
  ext.data <- list(YN = Y_star, XN = X_star)
  
  return(ext.data)
  
  
}


```



## Reproduction for artificial data 

The above functions are tested using data containing 1000 observations simulated from a bi-variate Gaussian random walk process with the covariance matrix equal to the identity matrix of order 2.

```{R}
#| echo: true

#Basic Model Test
y = apply(matrix(rnorm(2000), ncol = 2), 2, cumsum)

Y = y[2:1000,]
X = cbind(1, y[1:999,])
S = 1000
priors = calc.priors(p = 1, X = X, Y = Y)

posteriors = calc.posteriors(p = 1, S = 1000, X = X, Y= Y, priors)
```



A.posterior:

```{R}
round(apply(posteriors$A.posterior, 1:2, mean),3)
```

B.posterior:

```{R}
round(apply(posteriors$B.posterior, 1:2, mean),3)
```

Sigma.posterior:

```{R}
round(apply(posteriors$Sigma.posterior, 1:2, mean),3)
```

```{R}
#| echo: true
##Extended model Test
inital.dum = prior.ex(y, p = 1)
XN <- inital.dum$XN
YN <- inital.dum$YN

X.ex <- rbind(XN, X)
Y.ex <- rbind(YN, Y)

priors.ext = calc.priors(p = 1, X = X.ex, Y = Y.ex)

posteriors.ext = calc.posteriors(p= 1,S = 1000, X = XN,Y=YN, priors = priors.ext)


```


A.posterior:

```{R}
round(apply(posteriors.ext$A.posterior, 1:2, mean),3)
```

B.posterior:

```{R}
round(apply(posteriors.ext$B.posterior, 1:2, mean),3)
```

Sigma.posterior:

```{R}
round(apply(posteriors.ext$Sigma.posterior, 1:2, mean))
```

## Empirical Estimation


```{R}
##Create Y and X


p = 2
y = ts(data[c(1:4, 5)])
T = nrow(y)
Y = y[(p+1):T,]

X       = matrix(1,nrow(Y),1)

for (i in 1:p){
  X     = cbind(X,y[(p+1):T-i,])
}

A.hat = solve(t(X)%*%X)%*%(t(X)%*%Y)
Sigma.hat = diag(2)

emp.initial.dum <- prior.ex(data = y, p = 2)
X.emp <- rbind(emp.initial.dum$XN, X)
Y.emp <- rbind(emp.initial.dum$YN, Y)

priors.emp = calc.priors(p = 2, X = X.emp, Y = Y.emp)
posteriors.emp = calc.posteriors(p = 2,S = 1000, X = X, Y= Y, priors.emp)



```


A.posterior:

```{R}
round(apply(posteriors.emp$A.posterior, 1:2, mean),3)
```

B.posterior:

```{R}
round(apply(posteriors.emp$B.posterior, 1:2, mean),3)
```

Sigma.posterior:

```{R}
round(apply(posteriors.emp$Sigma.posterior, 1:2, mean),3)
```

```{R}
#IRFs
A.posterior <- posteriors.emp$A.posterior
B.posterior <- posteriors.emp$B.posterior

SignRestrictions <- function(sign.restrictions, posteriors){
  
  A.posterior   = posteriors$A.posterior
  B.posterior = posteriors$B.posterior
  B1.posterior = posteriors$B1.posterior
  Sigma.posterior = posteriors$Sigma.posterior
  
  S = dim(A.posterior)[3]
  N = dim(B.posterior)[1]
  p = (dim(B1.posterior)[2]-1)/N
  
  R1            = diag(sign.restrictions)
  B0.draws      = array(NA,c(N,N,S))
  B1.draws      = array(NA,c(N,(1+N*p),S))
  pb = txtProgressBar(min = 0, max = S, initial = 0)
for (s in 1:S){
  
  setTxtProgressBar(pb, s)
  
  B0.tilde <-B.posterior[,,s]
  B1.tilde <-  B1.posterior[,,s]
  A <- A.posterior[,,s]
  Sigma <- Sigma.posterior[,,s]
  
  sign.restrictions.do.not.hold = TRUE

  i=1
  
  while (sign.restrictions.do.not.hold){
    X           = matrix(rnorm(N*N),N,N)
    QR          = qr(X, tol = 1e-10)
    Q           = qr.Q(QR,complete=TRUE)
    R           = qr.R(QR,complete=TRUE)
    Q           = t(Q %*% diag(sign(diag(R))))
    B0          = Q%*%B0.tilde 
    B0.inv      = solve(B0) 
    # check       = prod(R1 %*% B0.inv %*% diag(N)[,1] > 0) # Check reponse at time 0
    check       = prod(R1 %*% B0.inv %*% diag(N)[,1] >= 0)
    
    
    if (check==1){sign.restrictions.do.not.hold=FALSE}
    i=i+1
  }
  B1            = Q%*%B1.tilde 
  B0.draws[,,s] = B0
  B1.draws[,,s] = B1

}
  draws = list(B0.draws = B0.draws,B1.draws = B1.draws,i = i)
  return (draws)
}
  
sign.restictions = c(1,1,-1,1,-1)
posteriors = posteriors.emp
draws.emp <- SignRestrictions(sign.restictions, posteriors = posteriors.emp)

B0.draws = draws.emp$B0.draws
B1.draws = draws.emp$B1.draws

A.posterior <- array(NA,c(N*p+1,N,S))
B.posterior       = array(NA,c(N,N,S))
S.check <- array(NA,c(N,N,S))

for (s in 1:S){
  #A.posterior[,,s] <- t(B1.draws[,,s]) %*% B0.draws[,,s]
  #B.posterior[,,s] <- solve(B0.draws[,,s])
}





h = 20
S = 1000
N = ncol(Y)
IRF.posterior     = array(NA,c(N,N,h+1,S))
IRF.inf.posterior = array(NA,c(N,N,S))
FEVD.posterior    = array(NA,c(N,N,h+1,S))
J                 = cbind(diag(N),matrix(0,N,N*(p-1)))

for (s in 1:S){
  A.bold          = rbind(t(A.posterior[2:(1+N*p),,s]),cbind(diag(N*(p-1)),matrix(0,N*(p-1),N)))
  IRF.inf.posterior[,,s]          = J %*% solve(diag(N*p)-A.bold) %*% t(J) %*% B.posterior[,,s]
  
  A.bold.power    = A.bold
  for (i in 1:(h+1)){
    if (i==1){
      IRF.posterior[,,i,s]        = B.posterior[,,s]
    } else {
      IRF.posterior[,,i,s]        = J %*% A.bold.power %*% t(J) %*% B.posterior[,,s]
      A.bold.power                = A.bold.power %*% A.bold
    }
    for (n in 1:N){
      for (nn in 1:N){
        FEVD.posterior[n,nn,i,s]  = sum(IRF.posterior[n,nn,1:i,s]^2)
      }
    }
    FEVD.posterior[,,i,s]         = diag(1/apply(FEVD.posterior[,,i,s],1,sum))%*%FEVD.posterior[,,i,s]
  }
}
FEVD.posterior    = 100*FEVD.posterior


# save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k002.RData")
save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k1.RData")
load("irf-fevd-k1.RData")



IRFs.k1           = apply(IRF.posterior[,1,,],1:2,mean)
IRFs.inf.k1       = apply(IRF.inf.posterior[,1,],1,mean)
rownames(IRFs.k1) = colnames(Y)

IRFs.k1.hdi    = apply(IRF.posterior[,1,,],1:2,hdi, credMass=0.68)
hh          = 1:5


par(mfrow=c(3,2), mar=c(4,4.5,2,2),cex.axis=1.5, cex.lab=1.5)
for (n in 1:5){
  ylims     = range(IRFs.k1[n,hh],IRFs.k1.hdi[,n,hh])
  plot(hh,IRFs.k1[n,hh], type="l", ylim=ylims, axes=FALSE, xlab="", ylab=rownames(IRFs.k1)[n])
  if (n==5 | n==6){
    axis(1,c(1,2,5,9),c("","1 quarter","1 year","2 years"))
  } else {
    axis(1,c(1,2,5,9),c("","","",""))
  }
  axis(2,c(ylims[1],0,ylims[2]),round(c(ylims[1],0,ylims[2]),3))
  polygon(c(hh,(h+1):1), c(IRFs.k1.hdi[1,n,hh],IRFs.k1.hdi[2,n,(h+1):1]))
  abline(h=0)
  lines(hh, IRFs.k1[n,hh],lwd=2)
}







```



## References {.unnumbered}



