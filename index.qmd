---
title: "Examining the Heterogeneours Effects of Monetary Policy on State-specific Unemployment in Australia: A Structural Vector Autoregression Analysis"
author: "Django Trueman-Greinke"

execute:
  echo: false
  
bibliography: references.bib
---

> **Abstract.** Using data from the Australian Bureau of Statistics, this paper attempts to understand how changes in monetary policy impact unemployment levels in different Australian states using a Structural Vector Autoregression (SVAR) approach.

> **Keywords.** Monetary policy, Unemployement, Regional Effects, Impluse Response Function, Structural Vector Autoregressions, Australia 

# Introduction

This research projects makes use of Bayesian SVARs in order to determine how monetary policy shocks affect Australian states in different ways. To capture monetary policy shocks the cash rate target is used which is set by the Royal Bank of Australia. It the operational target the implementation of monetary policy.State-specific unemployment levels are used as an indicator for the state-level economy.

Four states are chosen to investigate, Queensland, New South Wales, Victoria, and Western Australia. This leads to four separate systems of equations. These systems are estimated using a basic model and an extended model. The extended model is based on a combination of the dummy initial observation and sum of coefficients priors first introduced by Doan, Litterman, and Sims (1984). A simulation of data is performed in order to test the functions to estimate both the basic and extended model.

Impulse response functions are presented, demonstrating how both the models and states differ. An attempt at creating a function to model the heteroskedasticity is also made at the end of the paper, however the practical implementation of this was unsuccessful.


# Data

```{r load packages}
#| warning: false
#| echo: false
library(lubridate)
library(xtable)
library(mvtnorm)
library(plot3D)
library(HDInterval)
```


```{r Data}
#| echo: false
#| eval: true
#| message: false
#| warning: false

# I have put eval=False above as I do not want to run this chunk each time. I use the next chunk to save this data and load data using the third chunk for computational speed and to avoid data extraction errors

##Nominal GDP per capita
real.gdp <- readrba::read_rba(series_id = "GGDPCVGDP") 
real.gdp_temp <- xts::xts(real.gdp$value, real.gdp$date)
log.rgdp = log(real.gdp_temp)

##Cash Rate Target
crt <- readrba::read_rba(series_id = "FOOIRATCR") 
crt_temp <- xts::xts(crt$value, crt$date)

##Money Supply log
MS <- readrba::read_rba(series_id = "DMAM1N") 
MS_temp <- xts::xts(MS$value, MS$date)
log.MS <- log(MS_temp)

##Consumer Price Index
CPI <- readrba::read_rba(series_id = "GCPIAG") 
CPI_temp <- xts::xts(CPI$value, CPI$date)
log.CPI <- log(CPI_temp)


##QLD Unemployment Rate

UER.QLD <- readabs::read_abs(series_id = "A84423284T") 
UER.QLD_temp <- xts::xts(UER.QLD$value, UER.QLD$date - days(1))

##NSW Unemployment Rate

UER.NSW <- readabs::read_abs(series_id = "A84423270C") 
UER.NSW_temp <- xts::xts(UER.NSW$value, UER.NSW$date - days(1))

##VIC Unemployment Rate

UER.VIC <- readabs::read_abs(series_id = "A84423354L") 
UER.VIC_temp <- xts::xts(UER.VIC$value, UER.VIC$date - days(1))

##WA Unemployment Rate

UER.WA <- readabs::read_abs(series_id = "A84423326C") 
UER.WA_temp <- xts::xts(UER.WA$value, UER.WA$date - days(1))



data <- as.data.frame(merge(log.rgdp, log.CPI, crt_temp, log.MS, UER.QLD_temp, UER.NSW_temp, UER.VIC_temp, UER.WA_temp))

names <- c("Log(Real GDP)","Log(Consumer Price Index)", "Cash Rate Target", "Log(Money Supply)", "Unemployment Rate: Queensland", "Unemployment Rate: New South Wales","Unemployment Rate: Victoria","Unemployment Rate: Western Australia")

data <- na.omit(data)[1:132,]

colnames(data) <- names

```

```{r save data}
#| eval: false
# Save data here so that you do not have pull data from ABS each time you run
save.image(file = "ProjectData.RData")
```

```{r load data}
#| eval: false
load(file = "ProjectData.RData")
```


The data required can be taken directly from either the Australian Bureau of Statistics or the Royal Bank of Australia, who, together, provide the required data from 1990 to 2022 on real GDP, the Cash Rate Target, Money Supply, the Consumer Price Index, and the state-specific unemployment rate for Queensland, New South Wales, Victoria, and Western Australia. Logs have been taken of real GDP, Money Supply, and the Consumer Price Index.

Below are plots of each of the variables over time. There are clear trends in the data, and it is clear that the unemployment rates in each of the states are closely linked.

```{r plots}
#| echo: false
#| message: false
#| warning: false

dates <- as.Date(rownames(data),format = "%Y-%m-%d")

units <- c("","", "", "", "Percent", "Percent", "Percent", "Percent")

par(mfrow=c(2,2), mar=c(4,4,4,4))
#alternative margins for figures
# par(mfrow=c(4,2), mar=c(2,2,2,2))
for (i in 1:8){
  plot(dates, y=data[,i], main = paste(names[i]), ylab = paste(units[i]),xlab = "Date",type = "l",col = "blue",lwd = 2)
  
}

```

# Preliminary Data Analysis

## ACF and PACF plots
Below are the ACF and PACF plots for each of the variables. These show the memory properties of the data. Each pair of plots have similar shapes with the ACFs showing a strong positive, gradually decaying pattern, while the PACFs are all insignificant after the first lag. This suggests that many or all of the variables are likely to follow a random walk with drift process.

```{r (P)ACF plots}



par(mfrow=c(2,2), mar=c(4,4,4,4))
for(i in 1:8){
  acf(data[,i], main = paste(names[i]) )
pacf(data[,i], main = paste(names[i]))
}

```

## Integration Order Verification
Dickey-Fuller tests were run on each of the variables to determine the integration order, results are below. All of the variables have a single unit-root except for the Cash Rate Target. This matches the interpretation from the ACF and PACF plots.
```{r Integration}
#| echo: false
#| message: false
#| warning: false

results.adf0 <- data.frame("Variable" = character(),"Lag Order" = numeric(), "ADF Statistic" = numeric(), "p value" = numeric())


for (i in 1:8){
adf = tseries::adf.test(data[,i], k = 4)
results.adf0[i,1] <- paste(names[i])
results.adf0[i,2] <- adf$parameter
results.adf0[i,3] <- adf$statistic
results.adf0[i,4] <- adf$p.value

}


results.adf1 <- data.frame("Variable" = character(),"Lag Order" = numeric(), "ADF Statistic" = numeric(), "p value" = numeric())
for (i in 1:8){
  if (results.adf0[i,4]>0.05 & results.adf0[i,4]<1){
diff_adf = tseries::adf.test(diff(data[,i]), k = 3)
results.adf1[i,1] <- paste(names[i])
results.adf1[i,2] <- diff_adf[2]
results.adf1[i,3] <- diff_adf[1]
results.adf1[i,4] <- diff_adf[4]
  } else{
results.adf1[i,1] <- paste(names[i])
results.adf1[i,2] <- "N/A"
results.adf1[i,3] <- "N/A"
results.adf1[i,4] <- "N/A" }
}



# print(results.adf0)
# print(results.adf1)
# print(results.adf2)

rmarkdown::paged_table(results.adf0)
rmarkdown::paged_table(results.adf1)


```

# Methodology

This paper utilizes the following Bayesian SVAR model to capture the dynamics between the variables. 


\begin{align}
B_0 Y_t = b_0 + B_1 y_{t-1} +\dots +B_p y_{t-p} + u_t
\end{align} \begin{align}
u_t|Y_{t-1}~iid(0_N,I_N)
\end{align}


Where:

* $Y_{t}$ is an $N\times 1$ vector of endogenous variables described above.

* $B_0$ is an $N \times N$ structural matrix capturing contemporaneous relationships between variables.

* $u_t$ is an $N\times 1$ vector of independent structural shocks, conditional on $Y_{t-1}$.

The estimation of this model and subsequent calculation of the impulse response functions is the primary analysis in this paper.

The structural form model can be represented in it's reduced form by:

$$\begin{align}
\   y_t &= \mu_0 + A_1 y_{t-1} + \dots + A_p y_{t-p} + \varepsilon_t\\
\end{align}$$
$$\begin{align}
\ \varepsilon_t| Y_{t-1} \sim _{iid} ( 0, \Sigma)\\
\end{align}$$
$$\begin{align}
\Sigma &= B_0^{-1}B_0^{-1'}\\
\end{align}$$






# Modelling Framework

## Basic Model

Presenting the likelihood function as a normal-inverse Wishart distribution for $(A,\Sigma)$ using matrix notation, we have:



$$\begin{gather}
Y = XA + E \\
\\ E|X \sim MN_{T \times N}(0_{T \times N},\Sigma,I_T) 
\end{gather}$$

$$\begin{gather}
L(A,\Sigma|Y,X) \propto det(\Sigma)^{-\frac{T}{2}} exp \left\{-\frac{1}{2} tr \left[ \Sigma^{-1}(Y-XA)'(Y-XA) \right] \right\} \\
\\ = det(\Sigma)^{-\frac{T}{2}} exp \left\{-\frac{1}{2} tr \left[ \Sigma^{-1}(A-\hat{A})'X'X(A-\hat{A}) \right] \right\} exp \left\{-\frac{1}{2} tr \left[\Sigma^{-1}(Y-X \hat{A})'(Y-X \hat{A}) \right] \right\} \\
\end{gather}$$

where:



$$Y_t=\begin{pmatrix}  GDP_t &= \text{Real GDP}
\\ CPI_t  &= \text{Consumer Price Index}
\\ CRT_p  &= \text{Cash Rate Target GDP}
\\ M1_t  &= \text{Money Supply}
\\ UR_t  &= \text{State Specific Unemployment Rate}
\end{pmatrix}$$


\begin{gather}
\hat{A} = (X'X)^{-1}X'Y
\end{gather}

Hence:

\begin{gather}
L(A,\Sigma|Y,X) = NIW_{K\times N}(\hat{A}, (X'X)^{-1},(Y-X\hat{A})'(Y-X\hat{A}), T-N-K)
\end{gather}


This leads to joint prior distribution for $(A, \Sigma)$ of the same form:

\begin{gather}

p(A,\Sigma) = p(A|\Sigma) p(\Sigma) \\
A|\Sigma \sim MN_{K \times N} (\underline{A}, \Sigma , \underline{V}) \\
\Sigma \sim IW_{N}(\underline{S},\underline{\nu})
\end{gather}

The full conditional posterior is, therefore, given by:

$$\begin{gather}
p(A,\Sigma |Y, X) = p(A|Y, X, \Sigma) p(\Sigma|Y,X) \\
p(A|Y,X,\Sigma) = MN_{K \times N} (\bar{A}, \Sigma , \bar{V}) \\
p(\Sigma|Y, X) = IW_{N}(\bar{S},\bar{\nu})
\end{gather}$$

with parameters:

\begin{gather}
\bar{V} = (X^{'}X+ \underline{V}^{-1})^{-1} \\ 
\\ \bar{A} = \bar{V}(X^{'}Y+\underline{V}^{-1} \underline{A}) \\ 
\\ \bar{\nu} = T + \underline{\nu} \\ 
\\ \bar{S} = \underline{S} + Y^{'}Y +  \underline{A}^{'}\underline{V}^{-1}\underline{A} - \bar{A}^{'}\bar{V}^{-1}\bar{A}
\end{gather}


The following function uses the Minnesota prior to set priors for $V$, $A$, $\nu,$ and $S$
```{R - Setting Priors}
#| echo: true
#| message: false
#| warning: false

calc.priors <- function(p, X, Y){
  
  
  
  A.hat = solve(t(X)%*%X)%*%(t(X)%*%Y)
  Sigma.hat = diag(ncol(Y))
  N = ncol(Y)
    
  #Setting Kappas
  kappa.1 <- 0.02^2
  kappa.2 <-100
  
  K = 1 + (p*N)
  
  
  A.prior     = matrix(0,nrow(A.hat),ncol(A.hat))
  A.prior[2:(N+1),] = diag(N)
  V.prior     = diag(c(kappa.2,kappa.1*((1:p)^(-2))%x%rep(1,N)))
  S.prior     = diag(diag(Sigma.hat))
  nu.prior    = N+1
  
  priors <- list(A.prior = A.prior , V.prior=V.prior, S.prior=S.prior, nu.prior=nu.prior)
  
  return(priors)
}

```




Using these priors and the function below, we can calculate posteriors $A$, $B$, and $\Sigma$

```{R }
#| echo: true
#| message: false
#| warning: false

calc.posteriors <- function (p, S, X, Y, priors){
  
  N = ncol(Y)
  A.prior <- priors$A.prior
  V.prior <- priors$V.prior
  S.prior <- priors$S.prior
  nu.prior <- priors$nu.prior
  
  V.bar.inv   = (t(X)%*%X) + diag(1/diag(V.prior))
  V.bar       = solve(V.bar.inv)
  
  A.bar       = V.bar%*%(t(X)%*%Y + diag(1/diag(V.prior))%*%A.prior)
  nu.bar      = nrow(Y) + nu.prior
  
  S.bar       = S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar
  S.bar.inv   = solve(S.bar)
 
 
  
  Sigma.posterior.inv   = rWishart(S, df=nu.bar, Sigma=S.bar.inv)
  Sigma.posterior   = apply(Sigma.posterior.inv,3,solve)
  Sigma.posterior   = array(Sigma.posterior,c(N,N,S))
  A.posterior       = array(rnorm(prod(c(dim(A.bar),S))),c(dim(A.bar),S))
  L                 = t(chol(V.bar))
  B.posterior = array(NA, c(N,N,S))
  B1.posterior = array(NA,c(N,(1+N*p),S))
  


  for (s in 1:S){
    chol.sigma = chol(Sigma.posterior[,,s])
    A.posterior[,,s]= A.bar + L%*%A.posterior[,,s]%*%chol.sigma
    B.posterior[,,s]= t(chol.sigma)
    B1.posterior[,,s]= B.posterior[,,s]%*%t(A.posterior[,,s])
  }
  
  posterior = list(A.posterior = A.posterior, B.posterior = B.posterior, Sigma.posterior = Sigma.posterior, B1.posterior = B1.posterior)
  
  return(posterior)
}

```

## Extended model formulation

To extend the model I augment the system using the 'sum of coefficients' and 'dummy initial observation' prior. The sum of coefficients prior takes the average of the lagged values and adds them to the basic equation. This is because these values are assumed to be a good forecast of future observations.

The 'dummy initial observation' prior adds a single dummy observation such that all values are set equal to the averages of initial conditions, up to a scaling factor.

In order to practically generate the additional rows the following steps should be taken.

Firstly the average of lagged values needs to be calculated, $y.bar$. This is done by finding the mean of the first $p$ values in the data. Next, values of of the scaling factors need to be selected, typically, as I have done, values equal to 1 are chosen.

Once this has been done, the rows can be created. The fine details of how this is done can be found in Carriero and Clark (2013).
```{R}
#| echo: true
prior.ex <- function(data, p, lambda_3 = 1, lambda_4 = 1){
  
  N = ncol(data)
  M = (N*p)+1
  
  in.obvs.Y <- matrix(data[1:p,], ncol = N)
  y.bar     = colMeans(in.obvs.Y)
    
  Y_star    = rbind(diag(y.bar)/lambda_3, y.bar/lambda_4)
  X_star    = as.matrix(c(rep(0, N), 1/lambda_4))
  for (i in 1:p) {
    X_star  = cbind(Y_star, X_star)
  }
  
  ext.data <- list(YN = Y_star, XN = X_star)
  
  return(ext.data)
  
}

```


# Reproduction for artificial data 

The above functions are tested using data containing 1000 observations simulated from a bi-variate Gaussian random walk process with the covariance matrix equal to the identity matrix of order 2. The results from this are very close to the true parameters of the model, and thus the basic and extended models are both working as intended.
```{R}
#| echo: true

#Basic Model Test
y = apply(matrix(rnorm(2000), ncol = 2), 2, cumsum)

Y = y[2:1000,]
X = cbind(1, y[1:999,])
S = 1000
priors = calc.priors(p = 1, X = X, Y = Y)

posteriors = calc.posteriors(p = 1, S = 1000, X = X, Y= Y, priors)
```


A.posterior:
```{R}
round(apply(posteriors$A.posterior, 1:2, mean),3)
```
B.posterior:
```{R}
round(apply(posteriors$B.posterior, 1:2, mean),3)
```
Sigma.posterior:
```{R}
round(apply(posteriors$Sigma.posterior, 1:2, mean),3)
```
```{R}
#| echo: true
##Extended model Test
inital.dum = prior.ex(y, p = 1)
XN <- inital.dum$XN
YN <- inital.dum$YN

X.ex <- rbind(XN, X)
Y.ex <- rbind(YN, Y)

priors.ext = calc.priors(p = 1, X = X.ex, Y = Y.ex)

posteriors.ext = calc.posteriors(p= 1, S = 1000, X = X.ex,Y=Y.ex, priors = priors.ext)


```

A.posterior:
```{R}
round(apply(posteriors.ext$A.posterior, 1:2, mean),3)
```
B.posterior:
```{R}
round(apply(posteriors.ext$B.posterior, 1:2, mean),3)
```
Sigma.posterior:
```{R}
round(apply(posteriors.ext$Sigma.posterior, 1:2, mean), 4)
```
# Empirical Estimation
Below are the impulse response functions for each of the different systems resulting from a shock to the cash rate target, representing a change in monetary policy. For each system there are two sets of IRFs, the first is calculated using the basic model, the second uses the extended model.

## Queensland



```{R} 
##Create Y and X for QLD


p = 5
y = ts(data[c(1:4, 5)])
T = nrow(y)
Y = y[(p+1):T,]

X       = matrix(1,nrow(Y),1)

for (i in 1:p){
  X     = cbind(X,y[(p+1):T-i,])
}

A.hat = solve(t(X)%*%X)%*%(t(X)%*%Y)
Sigma.hat = diag(2)

emp.initial.dum <- prior.ex(data = y, p)
X.emp <- rbind(emp.initial.dum$XN, X)
Y.emp <- rbind(emp.initial.dum$YN, Y)

priors.emp = calc.priors(p, X = X, Y = Y)
posteriors.emp.qld = calc.posteriors(p,S = 1000, X = X, Y= Y, priors.emp)

priors.emp.ext = calc.priors(p, X = X.emp, Y = Y.emp)
posteriors.emp.qld.ext = calc.posteriors(p,S = 1000, X = X, Y= Y, priors.emp)

```
### Basic Model Estimation
```{R}
#IRFs QLD basic
A.posterior <- posteriors.emp.qld$A.posterior
B.posterior <- posteriors.emp.qld$B.posterior

mcxs1  = "#05386B"
mcxs2  = "#379683"
mcxs3  = "#5CDB95"
mcxs4  = "#8EE4AF"
mcxs5  = "#EDF5E1"
purple = "#b02442"
mcxs1.rgb   = col2rgb(mcxs1)
mcxs1.shade1= rgb(mcxs1.rgb[1],mcxs1.rgb[2],mcxs1.rgb[3], alpha=120, maxColorValue=255)
mcxs2.rgb   = col2rgb(mcxs2)
mcxs2.shade1= rgb(mcxs2.rgb[1],mcxs2.rgb[2],mcxs2.rgb[3], alpha=120, maxColorValue=255)

h = 20
S = 1000
N = ncol(Y)
IRF.posterior     = array(NA,c(N,N,h+1,S))
IRF.inf.posterior = array(NA,c(N,N,S))
FEVD.posterior    = array(NA,c(N,N,h+1,S))
J                 = cbind(diag(N),matrix(0,N,N*(p-1)))

for (s in 1:S){
  A.bold          = rbind(t(A.posterior[2:(1+N*p),,s]),cbind(diag(N*(p-1)),matrix(0,N*(p-1),N)))
  IRF.inf.posterior[,,s]          = J %*% solve(diag(N*p)-A.bold) %*% t(J) %*% B.posterior[,,s]
  
  A.bold.power    = A.bold
  for (i in 1:(h+1)){
    if (i==1){
      IRF.posterior[,,i,s]        = B.posterior[,,s]
    } else {
      IRF.posterior[,,i,s]        = J %*% A.bold.power %*% t(J) %*% B.posterior[,,s]
      A.bold.power                = A.bold.power %*% A.bold
    }
    for (n in 1:N){
      for (nn in 1:N){
        FEVD.posterior[n,nn,i,s]  = sum(IRF.posterior[n,nn,1:i,s]^2)
      }
    }
    FEVD.posterior[,,i,s]         = diag(1/apply(FEVD.posterior[,,i,s],1,sum))%*%FEVD.posterior[,,i,s]
  }
}
FEVD.posterior    = 100*FEVD.posterior


# save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k002.RData")
save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k1.RData")
load("irf-fevd-k1.RData")



IRFs.k1           = apply(IRF.posterior[,3,,],1:2,mean)
IRFs.inf.k1       = apply(IRF.inf.posterior[,3,],1,mean)
rownames(IRFs.k1) = colnames(Y)
rownames(IRFs.k1)[5] = "Unemployment Rate: Queensland"

IRFs.k1.hdi    = apply(IRF.posterior[,3,,],1:2,hdi, credMass=0.68)
hh          = 1:21


par(mfrow=c(3,2), mar=c(4,4.5,2,2),cex.axis=1.5, cex.lab=1.5)
for (n in 1:N){
  ylims     = range(IRFs.k1[n,hh],IRFs.k1.hdi[,n,hh])
  plot(hh,IRFs.k1[n,hh], type="l", ylim=ylims, axes=FALSE, xlab="", ylab=rownames(IRFs.k1)[n])
  
    axis(1, at = c(12), labels = c("2.5year"))
  axis(2,c(ylims[1],0,ylims[2]),round(c(ylims[1],0,ylims[2]),3))
  polygon(c(hh,(h+1):1), c(IRFs.k1.hdi[1,n,hh],IRFs.k1.hdi[2,n,(h+1):1]), col=mcxs1.shade1,border=mcxs1.shade1)
  abline(h=0)
  lines(hh, IRFs.k1[n,hh],lwd=2,col=mcxs1)
}






```
### Extended Model Estimation
```{R}
#IRFs QLD ext
A.posterior <- posteriors.emp.qld.ext$A.posterior
B.posterior <- posteriors.emp.qld.ext$B.posterior

N = ncol(Y)
IRF.posterior     = array(NA,c(N,N,h+1,S))
IRF.inf.posterior = array(NA,c(N,N,S))
FEVD.posterior    = array(NA,c(N,N,h+1,S))
J                 = cbind(diag(N),matrix(0,N,N*(p-1)))

for (s in 1:S){
  A.bold          = rbind(t(A.posterior[2:(1+N*p),,s]),cbind(diag(N*(p-1)),matrix(0,N*(p-1),N)))
  IRF.inf.posterior[,,s]          = J %*% solve(diag(N*p)-A.bold) %*% t(J) %*% B.posterior[,,s]
  
  A.bold.power    = A.bold
  for (i in 1:(h+1)){
    if (i==1){
      IRF.posterior[,,i,s]        = B.posterior[,,s]
    } else {
      IRF.posterior[,,i,s]        = J %*% A.bold.power %*% t(J) %*% B.posterior[,,s]
      A.bold.power                = A.bold.power %*% A.bold
    }
    for (n in 1:N){
      for (nn in 1:N){
        FEVD.posterior[n,nn,i,s]  = sum(IRF.posterior[n,nn,1:i,s]^2)
      }
    }
    FEVD.posterior[,,i,s]         = diag(1/apply(FEVD.posterior[,,i,s],1,sum))%*%FEVD.posterior[,,i,s]
  }
}
FEVD.posterior    = 100*FEVD.posterior


# save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k002.RData")
save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k1.RData")
load("irf-fevd-k1.RData")



IRFs.k1           = apply(IRF.posterior[,3,,],1:2,mean)
IRFs.inf.k1       = apply(IRF.inf.posterior[,3,],1,mean)
rownames(IRFs.k1) = colnames(Y)
rownames(IRFs.k1)[5] = "Unemployment Rate: Queensland"

IRFs.k1.hdi    = apply(IRF.posterior[,3,,],1:2,hdi, credMass=0.68)
hh          = 1:21


par(mfrow=c(3,2), mar=c(4,4.5,2,2),cex.axis=1.5, cex.lab=1.5)
for (n in 1:N){
  ylims     = range(IRFs.k1[n,hh],IRFs.k1.hdi[,n,hh])
  plot(hh,IRFs.k1[n,hh], type="l", ylim=ylims, axes=FALSE, xlab="", ylab=rownames(IRFs.k1)[n])
  
    axis(1, at = c(12), labels = c("2.5year"))
  axis(2,c(ylims[1],0,ylims[2]),round(c(ylims[1],0,ylims[2]),3))
  polygon(c(hh,(h+1):1), c(IRFs.k1.hdi[1,n,hh],IRFs.k1.hdi[2,n,(h+1):1]), col=mcxs1.shade1,border=mcxs1.shade1)
  abline(h=0)
  lines(hh, IRFs.k1[n,hh],lwd=2,col=mcxs1)
}






```
## New South Wales
```{R} 
##Create Y and X for NSW


p = 5
y = ts(data[c(1:4, 6)])
T = nrow(y)
Y = y[(p+1):T,]

X       = matrix(1,nrow(Y),1)

for (i in 1:p){
  X     = cbind(X,y[(p+1):T-i,])
}

A.hat = solve(t(X)%*%X)%*%(t(X)%*%Y)
Sigma.hat = diag(2)

emp.initial.dum <- prior.ex(data = y, p)
X.emp <- rbind(emp.initial.dum$XN, X)
Y.emp <- rbind(emp.initial.dum$YN, Y)

priors.emp = calc.priors(p, X = X, Y = Y)
posteriors.emp.nsw = calc.posteriors(p,S = 1000, X = X, Y= Y, priors.emp)

priors.emp.ext = calc.priors(p, X = X.emp, Y = Y.emp)
posteriors.emp.nsw.ext = calc.posteriors(p,S = 1000, X = X, Y= Y, priors.emp)

```



### Basic Model Estimation
```{R}
#IRFs NSW
A.posterior <- posteriors.emp.nsw$A.posterior
B.posterior <- posteriors.emp.nsw$B.posterior

h = 20
S = 1000
N = ncol(Y)
IRF.posterior     = array(NA,c(N,N,h+1,S))
IRF.inf.posterior = array(NA,c(N,N,S))
FEVD.posterior    = array(NA,c(N,N,h+1,S))
J                 = cbind(diag(N),matrix(0,N,N*(p-1)))

for (s in 1:S){
  A.bold          = rbind(t(A.posterior[2:(1+N*p),,s]),cbind(diag(N*(p-1)),matrix(0,N*(p-1),N)))
  IRF.inf.posterior[,,s]          = J %*% solve(diag(N*p)-A.bold) %*% t(J) %*% B.posterior[,,s]
  
  A.bold.power    = A.bold
  for (i in 1:(h+1)){
    if (i==1){
      IRF.posterior[,,i,s]        = B.posterior[,,s]
    } else {
      IRF.posterior[,,i,s]        = J %*% A.bold.power %*% t(J) %*% B.posterior[,,s]
      A.bold.power                = A.bold.power %*% A.bold
    }
    for (n in 1:N){
      for (nn in 1:N){
        FEVD.posterior[n,nn,i,s]  = sum(IRF.posterior[n,nn,1:i,s]^2)
      }
    }
    FEVD.posterior[,,i,s]         = diag(1/apply(FEVD.posterior[,,i,s],1,sum))%*%FEVD.posterior[,,i,s]
  }
}
FEVD.posterior    = 100*FEVD.posterior


# save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k002.RData")
save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k1.RData")
load("irf-fevd-k1.RData")



IRFs.k1           = apply(IRF.posterior[,3,,],1:2,mean)
IRFs.inf.k1       = apply(IRF.inf.posterior[,3,],1,mean)
rownames(IRFs.k1) = colnames(Y)
rownames(IRFs.k1)[5] = "Unemployment Rate: New South Wales"

IRFs.k1.hdi    = apply(IRF.posterior[,3,,],1:2,hdi, credMass=0.68)
hh          = 1:(h+1)


par(mfrow=c(3,2), mar=c(4,4.5,2,2),cex.axis=1.5, cex.lab=1.5)
for (n in 1:N){
  ylims     = range(IRFs.k1[n,hh],IRFs.k1.hdi[,n,hh])
  plot(hh,IRFs.k1[n,hh], type="l", ylim=ylims, axes=FALSE, xlab="", ylab=rownames(IRFs.k1)[n])
  
    axis(1, at = c(12), labels = c("2.5year"))
  axis(2,c(ylims[1],0,ylims[2]),round(c(ylims[1],0,ylims[2]),3))
  polygon(c(hh,(h+1):1), c(IRFs.k1.hdi[1,n,hh],IRFs.k1.hdi[2,n,(h+1):1]), col=mcxs1.shade1,border=mcxs1.shade1)
  abline(h=0)
  lines(hh, IRFs.k1[n,hh],lwd=2,col=mcxs1)
}






```
### Extended Model Estimation
```{R}
#IRFs NSW
A.posterior <- posteriors.emp.nsw$A.posterior
B.posterior <- posteriors.emp.nsw$B.posterior

h = 20
S = 1000
N = ncol(Y)
IRF.posterior     = array(NA,c(N,N,h+1,S))
IRF.inf.posterior = array(NA,c(N,N,S))
FEVD.posterior    = array(NA,c(N,N,h+1,S))
J                 = cbind(diag(N),matrix(0,N,N*(p-1)))

for (s in 1:S){
  A.bold          = rbind(t(A.posterior[2:(1+N*p),,s]),cbind(diag(N*(p-1)),matrix(0,N*(p-1),N)))
  IRF.inf.posterior[,,s]          = J %*% solve(diag(N*p)-A.bold) %*% t(J) %*% B.posterior[,,s]
  
  A.bold.power    = A.bold
  for (i in 1:(h+1)){
    if (i==1){
      IRF.posterior[,,i,s]        = B.posterior[,,s]
    } else {
      IRF.posterior[,,i,s]        = J %*% A.bold.power %*% t(J) %*% B.posterior[,,s]
      A.bold.power                = A.bold.power %*% A.bold
    }
    for (n in 1:N){
      for (nn in 1:N){
        FEVD.posterior[n,nn,i,s]  = sum(IRF.posterior[n,nn,1:i,s]^2)
      }
    }
    FEVD.posterior[,,i,s]         = diag(1/apply(FEVD.posterior[,,i,s],1,sum))%*%FEVD.posterior[,,i,s]
  }
}
FEVD.posterior    = 100*FEVD.posterior


# save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k002.RData")
save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k1.RData")
load("irf-fevd-k1.RData")



IRFs.k1           = apply(IRF.posterior[,3,,],1:2,mean)
IRFs.inf.k1       = apply(IRF.inf.posterior[,3,],1,mean)
rownames(IRFs.k1) = colnames(Y)
rownames(IRFs.k1)[5] = "Unemployment Rate: New South Wales"

IRFs.k1.hdi    = apply(IRF.posterior[,3,,],1:2,hdi, credMass=0.68)
hh          = 1:(h+1)


par(mfrow=c(3,2), mar=c(4,4.5,2,2),cex.axis=1.5, cex.lab=1.5)
for (n in 1:N){
  ylims     = range(IRFs.k1[n,hh],IRFs.k1.hdi[,n,hh])
  plot(hh,IRFs.k1[n,hh], type="l", ylim=ylims, axes=FALSE, xlab="", ylab=rownames(IRFs.k1)[n])
  
    axis(1, at = c(12), labels = c("2.5year"))
  axis(2,c(ylims[1],0,ylims[2]),round(c(ylims[1],0,ylims[2]),3))
  polygon(c(hh,(h+1):1), c(IRFs.k1.hdi[1,n,hh],IRFs.k1.hdi[2,n,(h+1):1]), col=mcxs1.shade1,border=mcxs1.shade1)
  abline(h=0)
  lines(hh, IRFs.k1[n,hh],lwd=2,col=mcxs1)
}






```


## Victoria

```{R} 
##Create Y and X for VIC


p = 5
y = ts(data[c(1:4, 7)])
T = nrow(y)
Y = y[(p+1):T,]

X       = matrix(1,nrow(Y),1)

for (i in 1:p){
  X     = cbind(X,y[(p+1):T-i,])
}

A.hat = solve(t(X)%*%X)%*%(t(X)%*%Y)
Sigma.hat = diag(2)

emp.initial.dum <- prior.ex(data = y, p)
X.emp <- rbind(emp.initial.dum$XN, X)
Y.emp <- rbind(emp.initial.dum$YN, Y)

priors.emp = calc.priors(p, X = X, Y = Y)
posteriors.emp.vic = calc.posteriors(p,S = 1000, X = X, Y= Y, priors.emp)

priors.emp.ext = calc.priors(p, X = X.emp, Y = Y.emp)
posteriors.emp.vic.ext = calc.posteriors(p,S = 1000, X = X, Y= Y, priors.emp)

```

### Basic Model Estimation
```{R}
#IRFs VIC
A.posterior <- posteriors.emp.vic$A.posterior
B.posterior <- posteriors.emp.vic$B.posterior




S = 1000
N = ncol(Y)
IRF.posterior     = array(NA,c(N,N,h+1,S))
IRF.inf.posterior = array(NA,c(N,N,S))
FEVD.posterior    = array(NA,c(N,N,h+1,S))
J                 = cbind(diag(N),matrix(0,N,N*(p-1)))

for (s in 1:S){
  A.bold          = rbind(t(A.posterior[2:(1+N*p),,s]),cbind(diag(N*(p-1)),matrix(0,N*(p-1),N)))
  IRF.inf.posterior[,,s]          = J %*% solve(diag(N*p)-A.bold) %*% t(J) %*% B.posterior[,,s]
  
  A.bold.power    = A.bold
  for (i in 1:(h+1)){
    if (i==1){
      IRF.posterior[,,i,s]        = B.posterior[,,s]
    } else {
      IRF.posterior[,,i,s]        = J %*% A.bold.power %*% t(J) %*% B.posterior[,,s]
      A.bold.power                = A.bold.power %*% A.bold
    }
    for (n in 1:N){
      for (nn in 1:N){
        FEVD.posterior[n,nn,i,s]  = sum(IRF.posterior[n,nn,1:i,s]^2)
      }
    }
    FEVD.posterior[,,i,s]         = diag(1/apply(FEVD.posterior[,,i,s],1,sum))%*%FEVD.posterior[,,i,s]
  }
}
FEVD.posterior    = 100*FEVD.posterior


# save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k002.RData")
save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k1.RData")
load("irf-fevd-k1.RData")



IRFs.k1           = apply(IRF.posterior[,3,,],1:2,mean)
IRFs.inf.k1       = apply(IRF.inf.posterior[,3,],1,mean)
rownames(IRFs.k1) = colnames(Y)
rownames(IRFs.k1)[5] = "Unemployment Rate: Victoria"


IRFs.k1.hdi    = apply(IRF.posterior[,3,,],1:2,hdi, credMass=0.68)



par(mfrow=c(3,2), mar=c(4,4.5,2,2),cex.axis=1.5, cex.lab=1.5)
for (n in 1:N){
  ylims     = range(IRFs.k1[n,hh],IRFs.k1.hdi[,n,hh])
  plot(hh,IRFs.k1[n,hh], type="l", ylim=ylims, axes=FALSE, xlab="", ylab=rownames(IRFs.k1)[n])
  
    axis(1, at = c(12), labels = c("2.5year"))
  axis(2,c(ylims[1],0,ylims[2]),round(c(ylims[1],0,ylims[2]),3))
  polygon(c(hh,(h+1):1), c(IRFs.k1.hdi[1,n,hh],IRFs.k1.hdi[2,n,(h+1):1]), col=mcxs1.shade1,border=mcxs1.shade1)
  abline(h=0)
  lines(hh, IRFs.k1[n,hh],lwd=2,col=mcxs1)
}

```
### Extended Model Estimation
```{R}
#IRFs VIC
A.posterior <- posteriors.emp.vic.ext$A.posterior
B.posterior <- posteriors.emp.vic.ext$B.posterior




S = 1000
N = ncol(Y)
IRF.posterior     = array(NA,c(N,N,h+1,S))
IRF.inf.posterior = array(NA,c(N,N,S))
FEVD.posterior    = array(NA,c(N,N,h+1,S))
J                 = cbind(diag(N),matrix(0,N,N*(p-1)))

for (s in 1:S){
  A.bold          = rbind(t(A.posterior[2:(1+N*p),,s]),cbind(diag(N*(p-1)),matrix(0,N*(p-1),N)))
  IRF.inf.posterior[,,s]          = J %*% solve(diag(N*p)-A.bold) %*% t(J) %*% B.posterior[,,s]
  
  A.bold.power    = A.bold
  for (i in 1:(h+1)){
    if (i==1){
      IRF.posterior[,,i,s]        = B.posterior[,,s]
    } else {
      IRF.posterior[,,i,s]        = J %*% A.bold.power %*% t(J) %*% B.posterior[,,s]
      A.bold.power                = A.bold.power %*% A.bold
    }
    for (n in 1:N){
      for (nn in 1:N){
        FEVD.posterior[n,nn,i,s]  = sum(IRF.posterior[n,nn,1:i,s]^2)
      }
    }
    FEVD.posterior[,,i,s]         = diag(1/apply(FEVD.posterior[,,i,s],1,sum))%*%FEVD.posterior[,,i,s]
  }
}
FEVD.posterior    = 100*FEVD.posterior


# save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k002.RData")
save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k1.RData")
load("irf-fevd-k1.RData")



IRFs.k1           = apply(IRF.posterior[,3,,],1:2,mean)
IRFs.inf.k1       = apply(IRF.inf.posterior[,3,],1,mean)
rownames(IRFs.k1) = colnames(Y)
rownames(IRFs.k1)[5] = "Unemployment Rate: Victoria"


IRFs.k1.hdi    = apply(IRF.posterior[,3,,],1:2,hdi, credMass=0.68)



par(mfrow=c(3,2), mar=c(4,4.5,2,2),cex.axis=1.5, cex.lab=1.5)
for (n in 1:N){
  ylims     = range(IRFs.k1[n,hh],IRFs.k1.hdi[,n,hh])
  plot(hh,IRFs.k1[n,hh], type="l", ylim=ylims, axes=FALSE, xlab="", ylab=rownames(IRFs.k1)[n])
  
    axis(1, at = c(12), labels = c("2.5year"))
  axis(2,c(ylims[1],0,ylims[2]),round(c(ylims[1],0,ylims[2]),3))
  polygon(c(hh,(h+1):1), c(IRFs.k1.hdi[1,n,hh],IRFs.k1.hdi[2,n,(h+1):1]), col=mcxs1.shade1,border=mcxs1.shade1)
  abline(h=0)
  lines(hh, IRFs.k1[n,hh],lwd=2,col=mcxs1)
}

```

## Western Australia

```{R} 

##Create Y and X for WA


p = 5
y = ts(data[c(1:4, 8)])
T = nrow(y)
Y = y[(p+1):T,]

X       = matrix(1,nrow(Y),1)

for (i in 1:p){
  X     = cbind(X,y[(p+1):T-i,])
}

A.hat = solve(t(X)%*%X)%*%(t(X)%*%Y)
Sigma.hat = diag(2)

emp.initial.dum <- prior.ex(data = y, p)
X.emp <- rbind(emp.initial.dum$XN, X)
Y.emp <- rbind(emp.initial.dum$YN, Y)

priors.emp = calc.priors(p, X = X, Y = Y)
posteriors.emp.wa = calc.posteriors(p,S = 1000, X = X, Y= Y, priors.emp)

priors.emp.ext = calc.priors(p, X = X.emp, Y = Y.emp)
posteriors.emp.wa.ext = calc.posteriors(p,S = 1000, X = X, Y= Y, priors.emp)

```

### Basic Model Estimation
```{R}
#IRFs
A.posterior <- posteriors.emp.wa$A.posterior
B.posterior <- posteriors.emp.wa$B.posterior




S = 1000
N = ncol(Y)
IRF.posterior     = array(NA,c(N,N,h+1,S))
IRF.inf.posterior = array(NA,c(N,N,S))
FEVD.posterior    = array(NA,c(N,N,h+1,S))
J                 = cbind(diag(N),matrix(0,N,N*(p-1)))

for (s in 1:S){
  A.bold          = rbind(t(A.posterior[2:(1+N*p),,s]),cbind(diag(N*(p-1)),matrix(0,N*(p-1),N)))
  IRF.inf.posterior[,,s]          = J %*% solve(diag(N*p)-A.bold) %*% t(J) %*% B.posterior[,,s]
  
  A.bold.power    = A.bold
  for (i in 1:(h+1)){
    if (i==1){
      IRF.posterior[,,i,s]        = B.posterior[,,s]
    } else {
      IRF.posterior[,,i,s]        = J %*% A.bold.power %*% t(J) %*% B.posterior[,,s]
      A.bold.power                = A.bold.power %*% A.bold
    }
    for (n in 1:N){
      for (nn in 1:N){
        FEVD.posterior[n,nn,i,s]  = sum(IRF.posterior[n,nn,1:i,s]^2)
      }
    }
    FEVD.posterior[,,i,s]         = diag(1/apply(FEVD.posterior[,,i,s],1,sum))%*%FEVD.posterior[,,i,s]
  }
}
FEVD.posterior    = 100*FEVD.posterior


# save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k002.RData")
save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k1.RData")
load("irf-fevd-k1.RData")



IRFs.k1           = apply(IRF.posterior[,3,,],1:2,mean)
IRFs.inf.k1       = apply(IRF.inf.posterior[,3,],1,mean)
rownames(IRFs.k1) = colnames(Y)
rownames(IRFs.k1)[5] = "Unemployment Rate: Western Australia"

IRFs.k1.hdi    = apply(IRF.posterior[,3,,],1:2,hdi, credMass=0.68)



par(mfrow=c(3,2), mar=c(4,4.5,2,2),cex.axis=1.5, cex.lab=1.5)
for (n in 1:N){
  ylims     = range(IRFs.k1[n,hh],IRFs.k1.hdi[,n,hh])
  plot(hh,IRFs.k1[n,hh], type="l", ylim=ylims, axes=FALSE, xlab="", ylab=rownames(IRFs.k1)[n])
  
    axis(1, at = c(12), labels = c("2.5year"))
  axis(2,c(ylims[1],0,ylims[2]),round(c(ylims[1],0,ylims[2]),3))
  polygon(c(hh,(h+1):1), c(IRFs.k1.hdi[1,n,hh],IRFs.k1.hdi[2,n,(h+1):1]), col=mcxs1.shade1,border=mcxs1.shade1)
  abline(h=0)
  lines(hh, IRFs.k1[n,hh],lwd=2,col=mcxs1)
}






```
### Extended Model Estimation
```{R}
#IRFs
A.posterior <- posteriors.emp.wa.ext$A.posterior
B.posterior <- posteriors.emp.wa.ext$B.posterior




S = 1000
N = ncol(Y)
IRF.posterior     = array(NA,c(N,N,h+1,S))
IRF.inf.posterior = array(NA,c(N,N,S))
FEVD.posterior    = array(NA,c(N,N,h+1,S))
J                 = cbind(diag(N),matrix(0,N,N*(p-1)))

for (s in 1:S){
  A.bold          = rbind(t(A.posterior[2:(1+N*p),,s]),cbind(diag(N*(p-1)),matrix(0,N*(p-1),N)))
  IRF.inf.posterior[,,s]          = J %*% solve(diag(N*p)-A.bold) %*% t(J) %*% B.posterior[,,s]
  
  A.bold.power    = A.bold
  for (i in 1:(h+1)){
    if (i==1){
      IRF.posterior[,,i,s]        = B.posterior[,,s]
    } else {
      IRF.posterior[,,i,s]        = J %*% A.bold.power %*% t(J) %*% B.posterior[,,s]
      A.bold.power                = A.bold.power %*% A.bold
    }
    for (n in 1:N){
      for (nn in 1:N){
        FEVD.posterior[n,nn,i,s]  = sum(IRF.posterior[n,nn,1:i,s]^2)
      }
    }
    FEVD.posterior[,,i,s]         = diag(1/apply(FEVD.posterior[,,i,s],1,sum))%*%FEVD.posterior[,,i,s]
  }
}
FEVD.posterior    = 100*FEVD.posterior


# save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k002.RData")
save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k1.RData")
load("irf-fevd-k1.RData")



IRFs.k1           = apply(IRF.posterior[,3,,],1:2,mean)
IRFs.inf.k1       = apply(IRF.inf.posterior[,3,],1,mean)
rownames(IRFs.k1) = colnames(Y)
rownames(IRFs.k1)[5] = "Unemployment Rate: Western Australia"

IRFs.k1.hdi    = apply(IRF.posterior[,3,,],1:2,hdi, credMass=0.68)



par(mfrow=c(3,2), mar=c(4,4.5,2,2),cex.axis=1.5, cex.lab=1.5)
for (n in 1:N){
  ylims     = range(IRFs.k1[n,hh],IRFs.k1.hdi[,n,hh])
  plot(hh,IRFs.k1[n,hh], type="l", ylim=ylims, axes=FALSE, xlab="", ylab=rownames(IRFs.k1)[n])
  
    axis(1, at = c(12), labels = c("2.5year"))
  axis(2,c(ylims[1],0,ylims[2]),round(c(ylims[1],0,ylims[2]),3))
  polygon(c(hh,(h+1):1), c(IRFs.k1.hdi[1,n,hh],IRFs.k1.hdi[2,n,(h+1):1]), col=mcxs1.shade1,border=mcxs1.shade1)
  abline(h=0)
  lines(hh, IRFs.k1[n,hh],lwd=2,col=mcxs1)
}






```


### Intepretations

Each of the impulse response functions show how variables react to a shock to the cash rate target. There are eight different systems, a basic and extended model for each of the key Australian states. There are no noticeable differences in the shapes or characteristics of the IRFs between the basic and extended models in any of the states. 

The goal of this paper is to find how different states react to changes in monetary policy. Interestingly, the effect of a positive shock to the cash rate target appears lead to a short term drop unemployment levels in every state with the impact decreasing over time. The magnitude of the effect on unemployment is most obvious difference between states. In Western Australia a shock to the cash rate drops unemployment by 0.1068 initially which slowly increases back to its initial value, however not reaching it within 5 years. In New South Wales, the drop is much greater, at 0.1405, while Victoria's drop is only 0.0657, and Queensland's is 0.0899. There are clear differences between each state, with a monetary policy shock affecting New South Wales the most and Victoria the least. This is highly unexpected and likely means there are issues with the estimation strategy.

## Stochastic Volatility model using Gibbs sampler

\begin{align}

Y = X \beta +E
\\ E|X \sim N(0_T, diag(\sigma^2)) 
\\ \sigma^2 = (exp({h_1}),..., exp({h_T}))
\\ h_t \text{ - follows a Stochastic Volatility process}
\\ \beta \sim N(\underline\beta, \underline V_\beta)

\end{align}



```{R}
#| echo: true


##Gibbs
SVcommon.Gibbs.iteration = function(S, aux, priors){
  
  posteriors    = list(
    H           = matrix(NA,T,S),
    s           = matrix(NA,T,S),
    h0          = rep(NA,S),
    sigma.v2    = rep(NA,S)
  )
  
  # A single iteration of the Gibbs sampler for the SV component
  #
  # aux is a list containing:
  #   Y - a TxN matrix
  #   X - a TxK matrix
  #   H - a Tx1 matrix
  #   h0 - a scalar
  #   sigma.v2 - a scalar
  #   s - a Tx1 matrix
  #   A - a KxN matrix
  #   Sigma - an NxN matrix
  #   sigma2 - a Tx1 matrix
  #
  # priors is a list containing:
  #   h0.v - a positive scalar
  #   h0.m - a scalar
  #   sigmav.s - a positive scalar
  #   sigmav.nu - a positive scalar
  #   HH - a TxT matrix
  
  T             = dim(aux$Y)[1]
  N             = dim(aux$Y)[2]
  alpha.st      = c(1.92677,1.34744,0.73504,0.02266,0-0.85173,-1.97278,-3.46788,-5.55246,-8.68384,-14.65000)
  sigma.st      = c(0.11265,0.17788,0.26768,0.40611,0.62699,0.98583,1.57469,2.54498,4.16591,7.33342)
  pi.st         = c(0.00609,0.04775,0.13057,0.20674,0.22715,0.18842,0.12047,0.05591,0.01575,0.00115)
  
  Lambda        = solve(chol(aux$Sigma))
  Z             = rowSums( ( aux$Y - aux$X %*% aux$A ) %*% Lambda ) / sqrt(N)
  Y.tilde       = as.vector(log((Z + 0.0000001)^2))
  Ytilde.alpha  = as.matrix(Y.tilde - alpha.st[as.vector(aux$s)])
  
  # sampling initial condition
  ############################################################
  V.h0.bar      = 1/((1 / priors$h0.v) + (1 / aux$sigma.v2))
  m.h0.bar      = V.h0.bar*((priors$h0.m / priors$h0.v) + (aux$H[1] / aux$sigma.v2))
  h0.draw       = rnorm(1, mean = m.h0.bar, sd = sqrt(V.h0.bar))
  aux$h0        = h0.draw
  
  # sampling sigma.v2
  ############################################################
  sigma.v2.s    = priors$sigmav.s + sum(c(aux$H[1] - aux$h0, diff(aux$H))^2)
  sigma.v2.draw = sigma.v2.s / rchisq(1, priors$sigmav.nu + T)
  aux$sigma.v2  = sigma.v2.draw
  
  # sampling auxiliary states
  ############################################################
  Pr.tmp        = simplify2array(lapply(1:10,function(x){
    dnorm(Y.tilde, mean = as.vector(aux$H + alpha.st[x]), sd = sqrt(sigma.st[x]), log = TRUE) + log(pi.st[x])
  }))
  Pr            = t(apply(Pr.tmp, 1, function(x){exp(x - max(x)) / sum(exp(x - max(x)))}))
  s.cum         = t(apply(Pr, 1, cumsum))
  r             = matrix(rep(runif(T), 10), ncol = 10)
  ss            = apply(s.cum < r, 1, sum) + 1
  aux$s         = as.matrix(ss)
  
  
  # sampling log-volatilities using functions for tridiagonal precision matrix
  ############################################################
  Sigma.s.inv   = diag(1 / sigma.st[as.vector(aux$s)])
  D.inv         = Sigma.s.inv + (1 / aux$sigma.v2) * priors$HH
  b             = as.matrix(Ytilde.alpha / sigma.st[as.vector(aux$s)] + (aux$h0/aux$sigma.v2)*diag(T)[,1])
  lead.diag     = diag(D.inv)
  sub.diag      = mgcv::sdiag(D.inv, -1)
  D.chol        = mgcv::trichol(ld = lead.diag, sd = sub.diag)
  D.L           = diag(D.chol$ld)
  mgcv::sdiag(D.L,-1) = D.chol$sd
  x             = as.matrix(rnorm(T))
  a             = forwardsolve(D.L, b)
  draw          = backsolve(t(D.L), a + x)
  aux$H         = as.matrix(draw)
  aux$sigma2    = as.matrix(exp(draw))
  
   for (s in 1:S){
     posteriors$H[,s]        = aux$H
    posteriors$s[,s]        = aux$s
    posteriors$h0[s]        = aux$h0
    posteriors$sigma.v2[s]  = aux$sigma.v2
   }
  
  return(posteriors)
}
  
  
  
```


## References {.unnumbered}

Doan, T., R. Litterman, and C. A. Sims (1984): "Forecasting and Conditional
Projection Using Realistic Prior Distributions," Econometric Reviews, 3, 1-100.

Carriero, A., Clark, T. E., & Marcellino, M. (2015): "Bayesian VARs: Specification choices and forecast accuracy," Journal of Applied Econometrics,30, 46-73.
